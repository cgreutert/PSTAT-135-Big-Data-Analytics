{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Assignment 2\n\n## Due date/time: February 13, 2023 at 11:59 PM\n## Submit Jupyter notebook to class Gradescope\n\nVariable `data` shows where data is located. Modify it as needed"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "data = \"gs://pstat135-cg/notebooks/jupyter/data/\""}, {"cell_type": "markdown", "metadata": {}, "source": "## Data\n\nThis is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016. The data was taken from Kaggle. The `athlete_events` Dataset contains $271,116$ rows and $15$ columns and the NOC region dataset contains $230$ rows and $3$ columns. They will be merged together by the National Olympic Committee (NOC) region. Both files are comma separated.\n\n**Source:**\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, athlete_events, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#athlete_events.csv\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, noc_regions, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#noc_regions.csv\n\n**ATTRIBUTES:**\n\n**athlete_events.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:----:|:----:|:----|\n| ID |  integer | Unique number for each athlete |\n| Name | string | Athlete\u2019s name |\n| Sex | string | M or F |\n| Age | integer |  |\n| Height | integer | In centimeters |\n| Weight | integer | In kilograms |\n| Team | string | Team name |\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Games | string | Year and season |\n| Year | integer |  |\n| Season | string | Summer or Winter |\n| City | string | Host city |\n| Sport | string |  |\n| Event | string |  |\n| Medal | string | Gold, Silver, Bronze, or NA |\n\n**noc_regions.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:--|--|:--|\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Region | string |  |\n| notes | string |  |\n\n## Upload the data into Google Cloud Storage\n\nUse the paths above to download our two files and upload them to your Google bucket. For consistency use the following path:\n\n`gs://<BUCKET-NAME>/notebooks/jupyter/data/olympics-analysis`\n\nand upload the files into *olympics-analysis* directory.\n\nConfirm that files were uploaded successfully and are accessible via the notebook by the following gsutil command:"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "gs://pstat135-cg/notebooks/jupyter/data/olympics-analysis/\ngs://pstat135-cg/notebooks/jupyter/data/olympics-analysis/athlete_events.csv\ngs://pstat135-cg/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\n"}], "source": "!gsutil ls {data + \"olympics-analysis\"}"}, {"cell_type": "markdown", "metadata": {}, "source": "## Load the data into Spark\n\nWe can either ask Spark to infer the schema or we explicitely specify it ourselves. For this example we need to specify the schema explicitely since not all the columns will be converted the way we would like to by the default option.\n\nAs a reminder, here is how we can define a schema contained of two columns, one string and one integer:\n\n```python\nfrom pyspark.sql.types import StructField, StructType, StringType, LongType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"name\", StringType(), True)\n])\n\ndf = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(\"gs/path/to/file\")\n```\n\nModify this code to load athlete_events.csv. Call this DataFrame `athlete_events`:\n\n**Note:** We have \"NA\" values in our data. This could cause issues when loading the data. To overcome this we need to let Spark know that what string is representing `null` in the data. We can use the option/parameter `nullValue` (as used in the sample code above) and set it to \"NA\"."}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import StructField, StructType, StringType, LongType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"Name\", StringType(), True),\n  StructField(\"Sex\", StringType(), True),\n  StructField(\"Age\", LongType(), True),\n  StructField(\"Height\", LongType(), True),\n  StructField(\"Weight\", LongType(), True),\n  StructField(\"Team\", StringType(), True),\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Games\", StringType(), True),\n  StructField(\"Year\", LongType(), True),\n  StructField(\"Season\", StringType(), True),\n  StructField(\"City\", StringType(), True),\n  StructField(\"Sport\", StringType(), True),\n  StructField(\"Event\", StringType(), True),\n  StructField(\"Medal\", StringType(), True)\n])\n\nathlete_events = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(\"gs://pstat135-cg/notebooks/jupyter/data/olympics-analysis/athlete_events.csv\")"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the schema of this DataFrame:"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- ID: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: long (nullable = true)\n |-- Height: long (nullable = true)\n |-- Weight: long (nullable = true)\n |-- Team: string (nullable = true)\n |-- NOC: string (nullable = true)\n |-- Games: string (nullable = true)\n |-- Year: long (nullable = true)\n |-- Season: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Sport: string (nullable = true)\n |-- Event: string (nullable = true)\n |-- Medal: string (nullable = true)\n\n"}], "source": "athlete_events.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the first 5 rows:"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 0:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\n| ID|                Name|Sex|Age|Height|Weight|          Team|NOC|      Games|Year|Season|     City|        Sport|               Event|Medal|\n+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\n|  1|           A Dijiang|  M| 24|   180|    80|         China|CHN|1992 Summer|1992|Summer|Barcelona|   Basketball|Basketball Men's ...| null|\n|  2|            A Lamusi|  M| 23|   170|    60|         China|CHN|2012 Summer|2012|Summer|   London|         Judo|Judo Men's Extra-...| null|\n|  3| Gunnar Nielsen Aaby|  M| 24|  null|  null|       Denmark|DEN|1920 Summer|1920|Summer|Antwerpen|     Football|Football Men's Fo...| null|\n|  4|Edgar Lindenau Aabye|  M| 34|  null|  null|Denmark/Sweden|DEN|1900 Summer|1900|Summer|    Paris|   Tug-Of-War|Tug-Of-War Men's ...| Gold|\n|  5|Christine Jacoba ...|  F| 21|   185|    82|   Netherlands|NED|1988 Winter|1988|Winter|  Calgary|Speed Skating|Speed Skating Wom...| null|\n+---+--------------------+---+---+------+------+--------------+---+-----------+----+------+---------+-------------+--------------------+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "athlete_events.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "We won't use the following columns, let's drop them from the DataFrame in a persistent way:\n\n* ID\n* Games\n* Event"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "athlete_events = athlete_events.drop(*(\"ID\", \"Games\", \"Event\"))"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n|                Name|Sex|Age|Height|Weight|          Team|NOC|Year|Season|     City|        Sport|Medal|\n+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n|           A Dijiang|  M| 24|   180|    80|         China|CHN|1992|Summer|Barcelona|   Basketball| null|\n|            A Lamusi|  M| 23|   170|    60|         China|CHN|2012|Summer|   London|         Judo| null|\n| Gunnar Nielsen Aaby|  M| 24|  null|  null|       Denmark|DEN|1920|Summer|Antwerpen|     Football| null|\n|Edgar Lindenau Aabye|  M| 34|  null|  null|Denmark/Sweden|DEN|1900|Summer|    Paris|   Tug-Of-War| Gold|\n|Christine Jacoba ...|  F| 21|   185|    82|   Netherlands|NED|1988|Winter|  Calgary|Speed Skating| null|\n+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\nonly showing top 5 rows\n\n"}], "source": "athlete_events.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": " Now load noc_regions.csv. Call this DataFrame `noc_regions`:"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "myManualSchema = StructType([\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Region\", StringType(), True),\n  StructField(\"notes\", StringType(), True)\n])\n\nnoc_regions = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(\"gs://pstat135-cg/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\")"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----------+--------------------+\n|NOC|     Region|               notes|\n+---+-----------+--------------------+\n|AFG|Afghanistan|                null|\n|AHO|    Curacao|Netherlands Antilles|\n|ALB|    Albania|                null|\n|ALG|    Algeria|                null|\n|AND|    Andorra|                null|\n+---+-----------+--------------------+\nonly showing top 5 rows\n\n"}], "source": "noc_regions.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Caching\n\nSince we will be using these two DataFrames a lot in this notebook let's `cache()` them to speed up our execution. Caching allows the DataFrame to be loaded and persist in the memory. If we don't use this option, every time we execute an action our DataFrame gets loaded from our Cloud Storage, which is not ideal and will add to our execution time:\n\n**Note:** Caching is a lazy transformation. It will happen the first time you execute an action against the DataFrame, not when you cache that DataFrame."}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[Name: string, Sex: string, Age: bigint, Height: bigint, Weight: bigint, Team: string, NOC: string, Year: bigint, Season: string, City: string, Sport: string, Medal: string]"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.cache() "}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[NOC: string, Region: string, notes: string]"}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": "noc_regions.cache() "}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 1\n\nWhat is the minimum and maximum `year`?\n\n**PSTAT 234**: use `agg` to show both minimum and maximum values in a single output."}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 3:=============================>                             (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+---------+\n|min(Year)|max(Year)|\n+---------+---------+\n|     1896|     2016|\n+---------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql.functions import *\nathlete_events.agg(min(col('Year')), max(col('Year'))).show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 2\n\nIs the following statement True or False?\n\n> Averag age of female athletes who attended the olympic games after 1990 has raised when compared to the era before then."}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+------------------+\n|          avg(Age)|\n+------------------+\n|24.619499568593614|\n+------------------+\n\n+------------------+\n|          avg(Age)|\n+------------------+\n|22.034368070953438|\n+------------------+\n\n"}], "source": "athlete_events.filter((col('Year') > 1990) & (col('Sex') == 'F')).agg(avg(col(\"Age\"))).show()\nathlete_events.filter((col('Year') < 1990) & (col('Sex') == 'F')).agg(avg(col(\"Age\"))).show()"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": "# True: the average age for female athletes before 1990 was roughly 22 and has raised to 24.62 after 1990."}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 3\n\nHow many Gold medals were given to men from 1970 to 2000 (including both years)?"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+\n|count(Medal)|\n+------------+\n|       12746|\n+------------+\n\n"}], "source": "athlete_events.filter((col('Year') >= 1970) & (col('Year') <= 2010) & (col('Sex') == 'M')).agg(count(col(\"Medal\"))).show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 4\n\nHow many NOCs attended Summer Olympics 2016 in Rio de Janeiro?\n\nNOC stands for National Olympic Committee. Almost equivalent to a country."}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 15:=============================>                            (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+\n|count(NOC)|\n+----------+\n|       207|\n+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "athlete_events.filter((col('Year') == 2016) & (col('Season') == 'Summer') & (col('City') == 'Rio de Janeiro')).agg(countDistinct(col(\"NOC\"))).show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 5\n\nCreate two DataFrames, one for the Winter games and one for the Summer games; these DataFrames should include a list of all NOCs that have wone gold medals in the colympics, and their count. Sort these DataFrame by the count in a descending order. Call these DataFrames `winter_gold_count` and `summer_gold_count` respectively. Using these two, answer the following questions:\n\nWhich country has the highest gold medal count in the Winter Olympics? How about the Summer Olympics?"}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|CAN|  305|\n+---+-----+\nonly showing top 1 row\n\n+---+-----+\n|NOC|count|\n+---+-----+\n|USA| 2376|\n+---+-----+\nonly showing top 1 row\n\n"}], "source": "from pyspark.sql.functions import desc, col\nwinter_gold_count = athlete_events.filter((col('Season') == 'Winter') & (col('Medal') == 'Gold')).groupby(col('NOC')).count().orderBy(desc('count'))\nsummer_gold_count = athlete_events.filter((col('Season') == 'Summer') & (col('Medal') == 'Gold')).groupby(col('NOC')).count().orderBy(desc('count'))\nwinter_gold_count.show(1)\nsummer_gold_count.show(1)"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": "# Canada has the highest gold medal count in the Winter Olympics and the US has the highest in the Summer Olympics"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 6\n\nUsing the common field `NOC`, merge `summer_gold_count` and `noc_regions` DataFrames.\n\nWhich region takes the 10th place? This is based on the number of gold medals in all of the Summer Olympics in our dataset.\n\n**PSTAT 234**: repeat the same procedure using SQL."}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+---------+-----+\n|NOC|count|   Region|notes|\n+---+-----+---------+-----+\n|USA| 2376|      USA| null|\n|URS|  832|   Russia| null|\n|GBR|  635|       UK| null|\n|GER|  591|  Germany| null|\n|ITA|  518|    Italy| null|\n|FRA|  465|   France| null|\n|HUN|  432|  Hungary| null|\n|SWE|  352|   Sweden| null|\n|AUS|  342|Australia| null|\n|GDR|  339|  Germany| null|\n+---+-----+---------+-----+\nonly showing top 10 rows\n\n"}], "source": "summer_gold_count.join(noc_regions, ['NOC']).orderBy(desc('count')).show(10)"}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": "# GDR, or Germany, takes 10th place based on the gold medal counts."}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}, "vscode": {"interpreter": {"hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}}, "nbformat": 4, "nbformat_minor": 4}